{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello TensorFlow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koyo/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create a constant op\n",
    "# This op is added as a node to the default graph\n",
    "hello = tf.constant(\"Hello, TensorFlow!\")\n",
    "\n",
    "# seart a TF session\n",
    "sess = tf.Session()\n",
    "\n",
    "# run the op and get result\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n",
    "node3 = tf.add(node1, node2) # node3 = node1 + node2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1: Tensor(\"Const_3:0\", shape=(), dtype=float32) node2: Tensor(\"Const_4:0\", shape=(), dtype=float32)\n",
      "node3:  Tensor(\"Add:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"node1:\", node1, \"node2:\", node2)\n",
    "print(\"node3: \", node3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run(node1, node2):  [3.0, 4.0]\n",
      "sess.run(mode3):  7.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(\"sess.run(node1, node2): \", sess.run([node1, node2]))\n",
    "print(\"sess.run(mode3): \", sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Computational Graph\n",
    "- (1) Bulid graph(tensors) using TensorFlow operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n",
    "node3 = tf.add(node1, node2) # node3 = node1 + node2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (2) feed data and run graph(operation)\n",
    "sess.run(op)\n",
    " - (3) update variables in the graph(and return values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run(node1, node2):  [3.0, 4.0]\n",
      "sess.run(mode3):  7.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(\"sess.run(node1, node2): \", sess.run([node1, node2]))\n",
    "print(\"sess.run(mode3): \", sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder\n",
    " - 그래프는 만들어두고 실행시키는 상황에서 던져주고 싶으면?\n",
    " - node를 placeholder로 만들어주자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "\n",
    "adder_node = a + b # + provides a shortcut for tf.add(a,b)\n",
    "\n",
    "print(sess.run(adder_node, feed_dict={a:3, b:4.5}))\n",
    "print(sess.run(adder_node, feed_dict={a:[1,3], b:[2,4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2. Linear Regression\n",
    "\n",
    " - Hypothesis and cost function\n",
    " - H(x) = Wx + b\n",
    " - W = weight, b = bias, H = Hypothesis\n",
    " \n",
    "## 1. Build graph using TF operations\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/koyo/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# X and Y data\n",
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Our hypothesis XW + b\n",
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost(W, b) = 1/m ㄷ(H(x^i) - y^i)^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost/Loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [1., 2., 3., 4.]\n",
    "sess.run(tf.reduce_mean(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientDescent ( Magic ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Run/update graph adn get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.4632645 [1.2662098] [0.6575465]\n",
      "20 0.039714944 [0.8544829] [0.45102838]\n",
      "40 0.024380527 [0.8233085] [0.41310972]\n",
      "60 0.02203683 [0.8279928] [0.3921028]\n",
      "80 0.02001323 [0.8357319] [0.3735238]\n",
      "100 0.018176321 [0.8434191] [0.35595515]\n",
      "120 0.01650803 [0.8507747] [0.33922517]\n",
      "140 0.014992856 [0.8577874] [0.32328266]\n",
      "160 0.013616749 [0.86447084] [0.3080896]\n",
      "180 0.012366948 [0.87084025] [0.2936105]\n",
      "200 0.011231862 [0.8769102] [0.27981183]\n",
      "220 0.010200966 [0.8826951] [0.26666173]\n",
      "240 0.009264673 [0.8882079] [0.25412962]\n",
      "260 0.008414316 [0.89346176] [0.24218646]\n",
      "280 0.007642023 [0.8984687] [0.23080464]\n",
      "300 0.0069406093 [0.90324026] [0.21995763]\n",
      "320 0.0063035744 [0.90778756] [0.20962045]\n",
      "340 0.0057250117 [0.91212124] [0.1997691]\n",
      "360 0.005199541 [0.9162512] [0.1903807]\n",
      "380 0.004722309 [0.9201871] [0.18143354]\n",
      "400 0.004288877 [0.923938] [0.17290682]\n",
      "420 0.0038952297 [0.9275127] [0.16478087]\n",
      "440 0.0035376977 [0.9309193] [0.15703672]\n",
      "460 0.003213004 [0.9341658] [0.1496566]\n",
      "480 0.0029180998 [0.93725973] [0.14262334]\n",
      "500 0.0026502758 [0.94020826] [0.13592064]\n",
      "520 0.0024070248 [0.9430183] [0.12953289]\n",
      "540 0.0021860944 [0.94569623] [0.12344527]\n",
      "560 0.00198544 [0.9482482] [0.11764379]\n",
      "580 0.0018032143 [0.95068043] [0.11211501]\n",
      "600 0.0016377006 [0.9529983] [0.106846]\n",
      "620 0.0014873944 [0.9552072] [0.1018246]\n",
      "640 0.0013508695 [0.9573123] [0.09703919]\n",
      "660 0.0012268809 [0.9593185] [0.09247868]\n",
      "680 0.0011142717 [0.9612304] [0.08813249]\n",
      "700 0.0010119979 [0.96305245] [0.08399054]\n",
      "720 0.00091911247 [0.96478885] [0.08004328]\n",
      "740 0.00083475054 [0.9664436] [0.07628155]\n",
      "760 0.00075813715 [0.9680206] [0.07269661]\n",
      "780 0.0006885533 [0.96952343] [0.06928019]\n",
      "800 0.0006253552 [0.97095585] [0.06602427]\n",
      "820 0.00056795595 [0.9723208] [0.06292135]\n",
      "840 0.00051582896 [0.9736216] [0.05996428]\n",
      "860 0.00046848351 [0.9748614] [0.05714614]\n",
      "880 0.00042548092 [0.9760428] [0.05446046]\n",
      "900 0.00038642922 [0.9771686] [0.051901]\n",
      "920 0.00035096426 [0.9782416] [0.04946187]\n",
      "940 0.00031875225 [0.97926414] [0.04713736]\n",
      "960 0.00028949475 [0.9802388] [0.04492211]\n",
      "980 0.0002629217 [0.98116744] [0.04281089]\n",
      "1000 0.00023879188 [0.9820525] [0.04079894]\n",
      "1020 0.00021687231 [0.982896] [0.03888153]\n",
      "1040 0.00019696659 [0.9836998] [0.03705423]\n",
      "1060 0.00017888802 [0.9844659] [0.03531281]\n",
      "1080 0.00016246847 [0.98519593] [0.03365322]\n",
      "1100 0.00014755887 [0.9858916] [0.03207166]\n",
      "1120 0.00013401514 [0.9865546] [0.03056442]\n",
      "1140 0.00012171344 [0.9871865] [0.02912804]\n",
      "1160 0.00011054394 [0.9877887] [0.02775914]\n",
      "1180 0.00010039652 [0.9883626] [0.02645458]\n",
      "1200 9.118244e-05 [0.9889095] [0.02521132]\n",
      "1220 8.2814055e-05 [0.9894306] [0.0240265]\n",
      "1240 7.521321e-05 [0.98992723] [0.02289745]\n",
      "1260 6.8309455e-05 [0.99040085] [0.02182136]\n",
      "1280 6.2038926e-05 [0.99085194] [0.02079582]\n",
      "1300 5.6345056e-05 [0.9912818] [0.01981849]\n",
      "1320 5.1173698e-05 [0.9916916] [0.01888709]\n",
      "1340 4.6477286e-05 [0.992082] [0.01799946]\n",
      "1360 4.2211326e-05 [0.9924541] [0.01715356]\n",
      "1380 3.833763e-05 [0.99280876] [0.01634741]\n",
      "1400 3.4817913e-05 [0.99314666] [0.01557915]\n",
      "1420 3.1622716e-05 [0.99346876] [0.01484702]\n",
      "1440 2.8720895e-05 [0.9937757] [0.01414926]\n",
      "1460 2.6083537e-05 [0.99406826] [0.0134843]\n",
      "1480 2.3690349e-05 [0.99434704] [0.01285057]\n",
      "1500 2.1516107e-05 [0.99461263] [0.01224665]\n",
      "1520 1.9540696e-05 [0.9948659] [0.01167111]\n",
      "1540 1.7747043e-05 [0.99510723] [0.01112257]\n",
      "1560 1.6117861e-05 [0.99533707] [0.01059984]\n",
      "1580 1.4638946e-05 [0.99555624] [0.01010171]\n",
      "1600 1.3295736e-05 [0.9957651] [0.00962697]\n",
      "1620 1.207471e-05 [0.9959641] [0.00917453]\n",
      "1640 1.0966946e-05 [0.9961538] [0.00874336]\n",
      "1660 9.960198e-06 [0.99633455] [0.00833246]\n",
      "1680 9.045928e-06 [0.9965068] [0.00794087]\n",
      "1700 8.215741e-06 [0.996671] [0.00756765]\n",
      "1720 7.4615905e-06 [0.9968274] [0.00721197]\n",
      "1740 6.776689e-06 [0.99697655] [0.00687304]\n",
      "1760 6.154616e-06 [0.99711865] [0.00655003]\n",
      "1780 5.589756e-06 [0.9972541] [0.00624218]\n",
      "1800 5.0766316e-06 [0.9973831] [0.00594882]\n",
      "1820 4.610814e-06 [0.997506] [0.00566925]\n",
      "1840 4.18765e-06 [0.99762326] [0.00540285]\n",
      "1860 3.8034207e-06 [0.99773496] [0.00514895]\n",
      "1880 3.454347e-06 [0.99784136] [0.00490697]\n",
      "1900 3.1372763e-06 [0.9979428] [0.0046764]\n",
      "1920 2.8493612e-06 [0.9980395] [0.00445664]\n",
      "1940 2.5878687e-06 [0.99813163] [0.00424722]\n",
      "1960 2.350397e-06 [0.99821943] [0.00404763]\n",
      "1980 2.1347128e-06 [0.9983031] [0.00385743]\n",
      "2000 1.9387207e-06 [0.9983828] [0.00367617]\n"
     ]
    }
   ],
   "source": [
    "# Launch teh graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the Line\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.9387207e-06 [0.9983867] [0.00366733]\n",
      "20 1.7608622e-06 [0.9984625] [0.00349501]\n",
      "40 1.5991287e-06 [0.9985348] [0.00333077]\n",
      "60 1.4522963e-06 [0.99860364] [0.00317423]\n",
      "80 1.3191374e-06 [0.9986692] [0.00302509]\n",
      "100 1.1981975e-06 [0.99873173] [0.00288294]\n",
      "120 1.0880909e-06 [0.99879134] [0.00274748]\n",
      "140 9.881895e-07 [0.9988482] [0.00261837]\n",
      "160 8.9762426e-07 [0.99890226] [0.00249533]\n",
      "180 8.153166e-07 [0.9989538] [0.00237809]\n",
      "200 7.403421e-07 [0.999003] [0.00226635]\n",
      "220 6.723645e-07 [0.99904984] [0.00215985]\n",
      "240 6.1081727e-07 [0.9990945] [0.0020584]\n",
      "260 5.548089e-07 [0.999137] [0.00196171]\n",
      "280 5.0382596e-07 [0.9991776] [0.00186954]\n",
      "300 4.5755624e-07 [0.9992162] [0.0017817]\n",
      "320 4.1564394e-07 [0.999253] [0.00169799]\n",
      "340 3.7748532e-07 [0.9992881] [0.00161824]\n",
      "360 3.4290133e-07 [0.9993216] [0.0015422]\n",
      "380 3.1139115e-07 [0.99935335] [0.00146976]\n",
      "400 2.8288844e-07 [0.9993837] [0.00140075]\n",
      "420 2.5689232e-07 [0.99941266] [0.00133499]\n",
      "440 2.3337986e-07 [0.9994403] [0.0012723]\n",
      "460 2.1196057e-07 [0.9994666] [0.00121256]\n",
      "480 1.9249886e-07 [0.9994917] [0.00115561]\n",
      "500 1.7482934e-07 [0.99951553] [0.00110135]\n",
      "520 1.5878514e-07 [0.99953824] [0.00104964]\n",
      "540 1.4428984e-07 [0.9995599] [0.00100035]\n",
      "560 1.3102844e-07 [0.9995805] [0.00095338]\n",
      "580 1.19007645e-07 [0.9996002] [0.00090861]\n",
      "600 1.0806665e-07 [0.999619] [0.00086596]\n",
      "620 9.820991e-08 [0.9996369] [0.00082536]\n",
      "640 8.921008e-08 [0.9996538] [0.00078663]\n",
      "660 8.102442e-08 [0.9996701] [0.00074971]\n",
      "680 7.360556e-08 [0.99968565] [0.00071456]\n",
      "700 6.688541e-08 [0.99970025] [0.00068102]\n",
      "720 6.07555e-08 [0.9997145] [0.0006491]\n",
      "740 5.5187858e-08 [0.9997277] [0.00061866]\n",
      "760 5.0128037e-08 [0.99974066] [0.00058961]\n",
      "780 4.5515364e-08 [0.99975264] [0.00056197]\n",
      "800 4.136729e-08 [0.99976444] [0.0005356]\n",
      "820 3.757341e-08 [0.9997753] [0.00051049]\n",
      "840 3.4110617e-08 [0.999786] [0.00048656]\n",
      "860 3.0989217e-08 [0.9997959] [0.00046371]\n",
      "880 2.8178045e-08 [0.99980545] [0.00044203]\n",
      "900 2.557554e-08 [0.9998147] [0.00042126]\n",
      "920 2.3260194e-08 [0.9998232] [0.00040151]\n",
      "940 2.1132601e-08 [0.99983156] [0.00038276]\n",
      "960 1.9179083e-08 [0.99983954] [0.00036475]\n",
      "980 1.7419874e-08 [0.9998469] [0.00034768]\n",
      "1000 1.5835914e-08 [0.999854] [0.00033149]\n",
      "1020 1.43958045e-08 [0.99986106] [0.00031594]\n",
      "1040 1.30703866e-08 [0.9998675] [0.00030109]\n",
      "1060 1.1876584e-08 [0.9998736] [0.00028704]\n",
      "1080 1.0799131e-08 [0.99987954] [0.00027366]\n",
      "1100 9.806139e-09 [0.9998854] [0.00026077]\n",
      "1120 8.894214e-09 [0.9998906] [0.0002485]\n",
      "1140 8.082623e-09 [0.99989563] [0.00023689]\n",
      "1160 7.3544206e-09 [0.9999004] [0.00022591]\n",
      "1180 6.6850325e-09 [0.99990517] [0.00021541]\n",
      "1200 6.0673386e-09 [0.9999098] [0.00020525]\n",
      "1220 5.514385e-09 [0.99991393] [0.00019558]\n",
      "1240 5.010468e-09 [0.9999179] [0.00018644]\n",
      "1260 4.557876e-09 [0.9999216] [0.00017778]\n",
      "1280 4.144989e-09 [0.99992526] [0.00016955]\n",
      "1300 3.76806e-09 [0.99992883] [0.00016168]\n",
      "1320 3.418151e-09 [0.99993235] [0.00015404]\n",
      "1340 3.102836e-09 [0.9999355] [0.00014672]\n",
      "1360 2.8223752e-09 [0.9999385] [0.00013981]\n",
      "1380 2.5611986e-09 [0.9999413] [0.00013326]\n",
      "1400 2.3305848e-09 [0.999944] [0.00012708]\n",
      "1420 2.1168678e-09 [0.99994653] [0.00012122]\n",
      "1440 1.9312598e-09 [0.9999489] [0.00011567]\n",
      "1460 1.7595928e-09 [0.9999513] [0.00011037]\n",
      "1480 1.5952916e-09 [0.9999537] [0.00010525]\n",
      "1500 1.4456608e-09 [0.999956] [0.00010024]\n",
      "1520 1.3146035e-09 [0.99995816] [9.543606e-05]\n",
      "1540 1.1910638e-09 [0.99996006] [9.087672e-05]\n",
      "1560 1.0801765e-09 [0.9999619] [8.6568485e-05]\n",
      "1580 9.784268e-10 [0.9999637] [8.2495506e-05]\n",
      "1600 8.8770474e-10 [0.99996537] [7.864345e-05]\n",
      "1620 8.1388407e-10 [0.9999669] [7.500597e-05]\n",
      "1640 7.399687e-10 [0.99996835] [7.155844e-05]\n",
      "1660 6.7312084e-10 [0.9999698] [6.8299276e-05]\n",
      "1680 6.1642896e-10 [0.99997115] [6.521652e-05]\n",
      "1700 5.6108246e-10 [0.9999724] [6.229351e-05]\n",
      "1720 5.141156e-10 [0.9999736] [5.9531034e-05]\n",
      "1740 4.67234e-10 [0.9999748] [5.689651e-05]\n",
      "1760 4.274104e-10 [0.999976] [5.434066e-05]\n",
      "1780 3.8767212e-10 [0.9999772] [5.1846797e-05]\n",
      "1800 3.5002756e-10 [0.99997836] [4.938155e-05]\n",
      "1820 3.1791103e-10 [0.99997956] [4.6956047e-05]\n",
      "1840 2.8537292e-10 [0.9999805] [4.4608416e-05]\n",
      "1860 2.5996863e-10 [0.99998146] [4.240066e-05]\n",
      "1880 2.3321434e-10 [0.99998236] [4.031609e-05]\n",
      "1900 2.1204964e-10 [0.99998325] [3.83388e-05]\n",
      "1920 1.9226813e-10 [0.9999841] [3.6468802e-05]\n",
      "1940 1.7191344e-10 [0.9999848] [3.469815e-05]\n",
      "1960 1.5578887e-10 [0.9999855] [3.3024444e-05]\n",
      "1980 1.4203276e-10 [0.99998623] [3.1442145e-05]\n",
      "2000 1.2875508e-10 [0.9999869] [2.9951234e-05]\n"
     ]
    }
   ],
   "source": [
    "# Now we can use X and Y in place of x_data and y_data\n",
    "# # placeholders for a tensor that will be always fed using feed_dict\n",
    "# See http://stackoverflow.com/questions/36693740/\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train],feed_dict={X: [1, 2, 3], Y: [1,2,3]}) \n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 9.078261 [0.77002394] [-0.5213526] [-0.0045101  0.5713867  1.1472836  1.7231803  2.299077 ]\n",
      "20 0.33511013 [1.3716118] [-0.25271043] [1.114458  2.4864573 3.8584566 5.230456  6.602455 ]\n",
      "40 0.29249927 [1.3499238] [-0.16338651] [1.1834334 2.5345404 3.8856473 5.2367544 6.5878615]\n",
      "60 0.25544173 [1.327019] [-0.08064296] [1.2434801 2.5716085 3.899737  5.227865  6.5559936]\n",
      "80 0.22307916 [1.3056024] [-0.00332171] [1.2995745 2.6062138 3.912853  5.219492  6.526131 ]\n",
      "100 0.19481674 [1.2855883] [0.06893567] [1.351995  2.638552  3.925109  5.211666  6.4982233]\n",
      "120 0.17013486 [1.2668848] [0.13646095] [1.4009824 2.6687727 3.9365628 5.204353  6.472143 ]\n",
      "140 0.14858004 [1.2494063] [0.1995639] [1.4467616 2.6970139 3.9472666 5.197519  6.447771 ]\n",
      "160 0.12975606 [1.2330725] [0.2585342] [1.4895428 2.723406  3.9572692 5.1911325 6.424996 ]\n",
      "180 0.11331689 [1.2178085] [0.3136425] [1.5295222 2.7480695 3.9666169 5.1851645 6.4037113]\n",
      "200 0.09896049 [1.203544] [0.36514166] [1.5668832 2.7711177 3.975352  5.1795864 6.383821 ]\n",
      "220 0.086422876 [1.1902138] [0.41326812] [1.6017976 2.7926567 3.9835157 5.1743746 6.3652334]\n",
      "240 0.07547381 [1.1777564] [0.45824274] [1.634425  2.8127844 3.9911437 5.169503  6.3478627]\n",
      "260 0.06591182 [1.166115] [0.50027204] [1.664916  2.8315945 3.9982734 5.164952  6.33163  ]\n",
      "280 0.05756127 [1.155236] [0.53954864] [1.6934099 2.8491726 4.004935  5.1606975 6.31646  ]\n",
      "300 0.05026871 [1.1450696] [0.57625306] [1.7200379 2.8655996 4.0111613 5.156723  6.3022847]\n",
      "320 0.04390005 [1.1355687] [0.6105537] [1.7449219 2.8809505 4.016979  5.153008  6.2890368]\n",
      "340 0.03833819 [1.1266903] [0.6426079] [1.7681763 2.8952963 4.022416  5.149536  6.276656 ]\n",
      "360 0.033481065 [1.1183932] [0.6725629] [1.7899077 2.9087024 4.0274973 5.146292  6.265087 ]\n",
      "380 0.029239256 [1.1106396] [0.70055604] [1.810216  2.9212308 4.032246  5.143261  6.254276 ]\n",
      "400 0.025534844 [1.1033937] [0.72671604] [1.8291941 2.9329386 4.0366826 5.140427  6.2441716]\n",
      "420 0.022299755 [1.0966222] [0.75116277] [1.8469294 2.9438796 4.0408297 5.1377797 6.23473  ]\n",
      "440 0.019474562 [1.0902944] [0.77400833] [1.8635032 2.954104  4.0447044 5.1353054 6.2259064]\n",
      "460 0.01700728 [1.0843811] [0.79535776] [1.8789916 2.9636588 4.0483265 5.1329937 6.217661 ]\n",
      "480 0.0148526 [1.0788548] [0.81530887] [1.8934654 2.9725876 4.05171   5.130832  6.2099547]\n",
      "500 0.01297089 [1.0736907] [0.83395356] [1.9069917 2.9809322 4.054873  5.1288137 6.2027545]\n",
      "520 0.011327556 [1.0688645] [0.8513771] [1.9196317 2.98873   4.057828  5.126926  6.196024 ]\n",
      "540 0.009892444 [1.0643545] [0.8676597] [1.9314443 2.996017  4.06059   5.1251626 6.1897354]\n",
      "560 0.008639141 [1.0601399] [0.8828758] [1.9424831 3.002827  4.063171  5.1235147 6.1838584]\n",
      "580 0.007544632 [1.0562013] [0.8970953] [1.952799  3.009191  4.0655828 5.121975  6.1783667]\n",
      "600 0.006588783 [1.0525206] [0.9103837] [1.9624392 3.015138  4.0678368 5.1205354 6.173234 ]\n",
      "620 0.0057540424 [1.049081] [0.92280185] [1.9714482 3.0206957 4.0699434 5.1191907 6.1684384]\n",
      "640 0.005025039 [1.0458666] [0.9344068] [1.9798672 3.0258894 4.071912  5.1179338 6.163956 ]\n",
      "660 0.0043884055 [1.0428628] [0.9452517] [1.9877349 3.0307431 4.0737514 5.1167593 6.159768 ]\n",
      "680 0.003832423 [1.0400556] [0.9553863] [1.9950871 3.0352788 4.07547   5.1156616 6.1558533]\n",
      "700 0.003346882 [1.0374324] [0.9648573] [2.0019581 3.0395176 4.077077  5.1146364 6.152196 ]\n",
      "720 0.0029228488 [1.0349809] [0.97370785] [2.008379  3.0434785 4.078578  5.1136775 6.148777 ]\n",
      "740 0.0025525442 [1.0326899] [0.9819788] [2.0143793 3.04718   4.079981  5.1127815 6.145582 ]\n",
      "760 0.0022291727 [1.030549] [0.98970807] [2.0199866 3.0506394 4.081292  5.111945  6.142598 ]\n",
      "780 0.0019467421 [1.0285484] [0.99693114] [2.0252266 3.0538719 4.082517  5.111162  6.139807 ]\n",
      "800 0.001700104 [1.0266788] [1.0036811] [2.0301237 3.0568929 4.083662  5.1104317 6.1372004]\n",
      "820 0.0014847072 [1.0249316] [1.0099893] [2.0347    3.059716  4.084732  5.109748  6.1347637]\n",
      "840 0.0012966198 [1.0232987] [1.015884] [2.0389764 3.062354  4.085732  5.10911   6.132488 ]\n",
      "860 0.0011323354 [1.0217729] [1.0213932] [2.042973  3.0648198 4.086666  5.108513  6.1303596]\n",
      "880 0.0009888757 [1.020347] [1.0265411] [2.046708 3.067124 4.08754  5.107956 6.128372]\n",
      "900 0.0008635996 [1.0190144] [1.0313518] [2.0501976 3.0692766 4.0883555 5.1074343 6.126513 ]\n",
      "920 0.00075418624 [1.0177691] [1.0358477] [2.0534594 3.0712888 4.089118  5.106948  6.124777 ]\n",
      "940 0.00065863365 [1.0166054] [1.0400491] [2.0565076 3.0731692 4.0898314 5.106493  6.1231546]\n",
      "960 0.0005751945 [1.0155178] [1.0439754] [2.0593557 3.0749264 4.090497  5.1060677 6.1216383]\n",
      "980 0.00050232094 [1.0145017] [1.0476444] [2.0620177 3.0765686 4.09112   5.1056705 6.1202216]\n",
      "1000 0.0004386776 [1.0135518] [1.0510732] [2.064505  3.078103  4.0917006 5.1052985 6.1188965]\n",
      "1020 0.00038310216 [1.0126644] [1.0542774] [2.0668297 3.079537  4.0922446 5.104952  6.117659 ]\n",
      "1040 0.00033456663 [1.0118351] [1.0572718] [2.0690022 3.0808773 4.092753  5.104628  6.1165032]\n",
      "1060 0.00029217574 [1.01106] [1.0600702] [2.0710323 3.08213   4.0932274 5.104325  6.1154222]\n",
      "1080 0.00025516193 [1.0103358] [1.062685] [2.0729294 3.0833    4.093671  5.104042  6.1144123]\n",
      "1100 0.00022283569 [1.0096587] [1.0651286] [2.0747018 3.0843933 4.0940847 5.103776  6.113467 ]\n",
      "1120 0.00019460908 [1.0090262] [1.0674123] [2.0763586 3.0854154 4.094472  5.103529  6.112586 ]\n",
      "1140 0.00016995492 [1.0084351] [1.0695465] [2.0779068 3.0863705 4.0948343 5.103298  6.111762 ]\n",
      "1160 0.0001484205 [1.0078827] [1.071541] [2.0793538 3.087263  4.095173  5.103082  6.1109915]\n",
      "1180 0.00012961763 [1.0073663] [1.0734048] [2.080706  3.088097  4.0954885 5.10288   6.1102715]\n",
      "1200 0.000113192575 [1.0068839] [1.0751467] [2.0819697 3.0888767 4.095784  5.102691  6.1095986]\n",
      "1220 9.8851844e-05 [1.006433] [1.0767744] [2.0831504 3.0896053 4.09606   5.1025147 6.1089697]\n",
      "1240 8.632948e-05 [1.0060118] [1.0782954] [2.0842538 3.0902863 4.0963182 5.1023507 6.1083827]\n",
      "1260 7.539383e-05 [1.0056181] [1.0797166] [2.085285  3.090922  4.0965595 5.1021967 6.107834 ]\n",
      "1280 6.584181e-05 [1.0052503] [1.0810448] [2.0862486 3.0915167 4.0967846 5.1020527 6.107321 ]\n",
      "1300 5.750068e-05 [1.0049064] [1.0822862] [2.0871491 3.0920725 4.0969954 5.1019187 6.1068416]\n",
      "1320 5.021537e-05 [1.004585] [1.0834464] [2.0879908 3.0925915 4.0971923 5.101793  6.1063933]\n",
      "1340 4.3852247e-05 [1.0042847] [1.0845305] [2.0887773 3.0930767 4.097376  5.101675  6.105974 ]\n",
      "1360 3.8297712e-05 [1.0040042] [1.0855435] [2.0895123 3.0935302 4.097548  5.101566  6.1055837]\n",
      "1380 3.344607e-05 [1.003742] [1.0864902] [2.090199  3.0939536 4.097708  5.101463  6.1052175]\n",
      "1400 2.9208302e-05 [1.003497] [1.0873748] [2.0908408 3.0943496 4.0978584 5.101367  6.1048756]\n",
      "1420 2.5508929e-05 [1.003268] [1.0882016] [2.0914407 3.09472   4.0979986 5.101278  6.104557 ]\n",
      "1440 2.2277027e-05 [1.003054] [1.0889742] [2.0920012 3.0950656 4.09813   5.1011944 6.1042585]\n",
      "1460 1.9457158e-05 [1.002854] [1.0896959] [2.0925245 3.0953884 4.098252  5.1011157 6.1039796]\n",
      "1480 1.699104e-05 [1.0026672] [1.0903707] [2.0930142 3.0956905 4.0983667 5.1010427 6.1037188]\n",
      "1500 1.4839051e-05 [1.0024925] [1.0910013] [2.0934718 3.0959728 4.0984735 5.100975  6.1034756]\n",
      "1520 1.2958926e-05 [1.0023292] [1.0915906] [2.0938993 3.0962362 4.0985737 5.1009107 6.1032476]\n",
      "1540 1.1316969e-05 [1.0021768] [1.0921413] [2.0942988 3.0964828 4.098667  5.100851  6.103035 ]\n",
      "1560 9.883153e-06 [1.0020342] [1.0926559] [2.0946722 3.096713  4.0987544 5.1007953 6.102836 ]\n",
      "1580 8.630759e-06 [1.001901] [1.0931369] [2.0950212 3.0969286 4.098836  5.1007433 6.1026506]\n",
      "1600 7.5382004e-06 [1.0017765] [1.0935863] [2.095347  3.0971296 4.0989122 5.1006947 6.102477 ]\n",
      "1620 6.5837403e-06 [1.0016602] [1.0940063] [2.0956516 3.0973177 4.0989833 5.1006494 6.1023154]\n",
      "1640 5.749555e-06 [1.0015515] [1.0943987] [2.0959365 3.0974932 4.09905   5.100607  6.102164 ]\n",
      "1660 5.0210137e-06 [1.0014498] [1.0947657] [2.0962026 3.0976572 4.099112  5.100567  6.1020217]\n",
      "1680 4.384674e-06 [1.0013548] [1.0951085] [2.0964513 3.0978107 4.09917   5.1005297 6.101889 ]\n",
      "1700 3.8290423e-06 [1.0012662] [1.0954287] [2.0966837 3.0979543 4.099225  5.1004953 6.1017656]\n",
      "1720 3.344112e-06 [1.0011833] [1.095728] [2.096901  3.0980883 4.0992756 5.100463  6.10165  ]\n",
      "1740 2.9206535e-06 [1.0011058] [1.0960077] [2.0971036 3.0982132 4.0993223 5.100432  6.1015415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1760 2.5503257e-06 [1.0010334] [1.0962691] [2.0972934 3.0983303 4.099367  5.100404  6.1014404]\n",
      "1780 2.2272725e-06 [1.0009656] [1.0965135] [2.0974708 3.0984397 4.0994086 5.1003776 6.1013465]\n",
      "1800 1.94504e-06 [1.0009024] [1.096742] [2.0976365 3.098542  4.0994473 5.1003532 6.1012583]\n",
      "1820 1.6987411e-06 [1.0008434] [1.0969553] [2.0977912 3.0986376 4.0994835 5.10033   6.1011763]\n",
      "1840 1.4837309e-06 [1.0007881] [1.0971545] [2.0979357 3.0987265 4.0995173 5.1003084 6.101099 ]\n",
      "1860 1.2958783e-06 [1.0007366] [1.0973408] [2.0980709 3.09881   4.0995493 5.1002884 6.1010275]\n",
      "1880 1.131709e-06 [1.0006883] [1.0975149] [2.098197  3.0988874 4.0995784 5.100269  6.1009593]\n",
      "1900 9.882866e-07 [1.0006433] [1.0976776] [2.0983152 3.0989604 4.099606  5.100251  6.100897 ]\n",
      "1920 8.6325116e-07 [1.0006013] [1.0978296] [2.0984254 3.0990288 4.0996323 5.1002355 6.1008387]\n",
      "1940 7.540087e-07 [1.000562] [1.0979716] [2.0985284 3.0990925 4.099656  5.10022   6.100784 ]\n",
      "1960 6.585851e-07 [1.0005252] [1.0981042] [2.0986247 3.0991518 4.099679  5.100206  6.100733 ]\n",
      "1980 5.7517974e-07 [1.0004908] [1.0982282] [2.0987148 3.0992072 4.0996995 5.100192  6.1006846]\n",
      "2000 5.0238486e-07 [1.0004587] [1.0983442] [2.0987988 3.0992591 4.0997195 5.1001797 6.10064  ]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = X * W + b\n",
    "# cost/Loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the Line with new training data\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, hypo, _ = sess.run([cost, W, b, hypothesis, train], feed_dict={X: [1,2,3,4,5], Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    \n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val, hypo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0999928]\n",
      "[3.6000056]\n",
      "[2.6000106 4.6000004]\n"
     ]
    }
   ],
   "source": [
    " # Testing our model\n",
    "print(sess.run(hypothesis, feed_dict={X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3. Minimizing Cost\n",
    " - H(x) = Wx (+b)\n",
    " - cost(W) = 1/mㄷ(Wx^i - y^i)^2\n",
    " \n",
    " cost가 최저가 되는 w를 찾자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x125a7cbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X=[1,2,3]\n",
    "Y=[1,2,3]\n",
    "\n",
    "W = tf.placeholder(tf.float32)\n",
    "# Our hypothesis for linear model X * W\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost/Lost function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y ))\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Variables for plotting cost function\n",
    "W_val = []\n",
    "cost_val = []\n",
    "for i in range(-30, 50):\n",
    "    feed_W = i * 0.1\n",
    "    curr_cost, curr_W = sess.run([cost, W], feed_dict={W: feed_W})\n",
    "    W_val.append(curr_W)\n",
    "    cost_val.append(curr_cost)\n",
    "    \n",
    "# Show the cost function\n",
    "plt.plot(W_val, cost_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 13.254265 [0.02699786]\n",
      "1 3.7701018 [0.48106554]\n",
      "2 1.0723844 [0.72323495]\n",
      "3 0.30503386 [0.85239196]\n",
      "4 0.08676508 [0.92127573]\n",
      "5 0.024679892 [0.9580137]\n",
      "6 0.007020048 [0.9776073]\n",
      "7 0.0019967994 [0.98805726]\n",
      "8 0.0005679778 [0.9936305]\n",
      "9 0.00016156025 [0.99660295]\n",
      "10 4.5953766e-05 [0.99818826]\n",
      "11 1.3070625e-05 [0.99903375]\n",
      "12 3.717711e-06 [0.99948466]\n",
      "13 1.0573971e-06 [0.99972516]\n",
      "14 3.0069737e-07 [0.99985343]\n",
      "15 8.561619e-08 [0.9999218]\n",
      "16 2.4371616e-08 [0.9999583]\n",
      "17 6.9279515e-09 [0.99997777]\n",
      "18 1.9654358e-09 [0.99998814]\n",
      "19 5.6338934e-10 [0.9999937]\n",
      "20 1.5597834e-10 [0.99999666]\n"
     ]
    }
   ],
   "source": [
    "x_data = [1,2,3]\n",
    "y_data = [1,2,3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Our hypothesis for linear model X * W\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost/Loss function\n",
    "cost = tf.reduce_sum(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize: Gradient Descent using derivative: W -= Learning_rate * derivative\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * X - Y) * X)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -3.0\n",
      "1 0.7333336\n",
      "2 0.98222226\n",
      "3 0.9988148\n",
      "4 0.99992096\n",
      "5 0.9999947\n",
      "6 0.99999964\n",
      "7 0.99999994\n",
      "8 1.0\n",
      "9 1.0\n",
      "10 1.0\n",
      "11 1.0\n",
      "12 1.0\n",
      "13 1.0\n",
      "14 1.0\n",
      "15 1.0\n",
      "16 1.0\n",
      "17 1.0\n",
      "18 1.0\n",
      "19 1.0\n",
      "20 1.0\n",
      "21 1.0\n",
      "22 1.0\n",
      "23 1.0\n",
      "24 1.0\n",
      "25 1.0\n",
      "26 1.0\n",
      "27 1.0\n",
      "28 1.0\n",
      "29 1.0\n",
      "30 1.0\n",
      "31 1.0\n",
      "32 1.0\n",
      "33 1.0\n",
      "34 1.0\n",
      "35 1.0\n",
      "36 1.0\n",
      "37 1.0\n",
      "38 1.0\n",
      "39 1.0\n",
      "40 1.0\n",
      "41 1.0\n",
      "42 1.0\n",
      "43 1.0\n",
      "44 1.0\n",
      "45 1.0\n",
      "46 1.0\n",
      "47 1.0\n",
      "48 1.0\n",
      "49 1.0\n",
      "50 1.0\n",
      "51 1.0\n",
      "52 1.0\n",
      "53 1.0\n",
      "54 1.0\n",
      "55 1.0\n",
      "56 1.0\n",
      "57 1.0\n",
      "58 1.0\n",
      "59 1.0\n",
      "60 1.0\n",
      "61 1.0\n",
      "62 1.0\n",
      "63 1.0\n",
      "64 1.0\n",
      "65 1.0\n",
      "66 1.0\n",
      "67 1.0\n",
      "68 1.0\n",
      "69 1.0\n",
      "70 1.0\n",
      "71 1.0\n",
      "72 1.0\n",
      "73 1.0\n",
      "74 1.0\n",
      "75 1.0\n",
      "76 1.0\n",
      "77 1.0\n",
      "78 1.0\n",
      "79 1.0\n",
      "80 1.0\n",
      "81 1.0\n",
      "82 1.0\n",
      "83 1.0\n",
      "84 1.0\n",
      "85 1.0\n",
      "86 1.0\n",
      "87 1.0\n",
      "88 1.0\n",
      "89 1.0\n",
      "90 1.0\n",
      "91 1.0\n",
      "92 1.0\n",
      "93 1.0\n",
      "94 1.0\n",
      "95 1.0\n",
      "96 1.0\n",
      "97 1.0\n",
      "98 1.0\n",
      "99 1.0\n"
     ]
    }
   ],
   "source": [
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "# Set wrong model weights\n",
    "\n",
    "W = tf.Variable(-3.0)\n",
    "\n",
    "# Linear model\n",
    "hypothesis = X * W\n",
    "# cost/Loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize: Gradient Descent Magic\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    print(step, sess.run(W))\n",
    "    sess.run(train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional : compute_gradient and apply_gradient\n",
    "\n",
    " - 우리가 구한거랑 컴퓨터가 구해주는거랑 비교해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [37.333332, 5.0, [(37.333336, 5.0)]]\n",
      "1 [33.84889, 4.6266665, [(33.84889, 4.6266665)]]\n",
      "2 [30.689657, 4.2881775, [(30.689657, 4.2881775)]]\n",
      "3 [27.825287, 3.9812808, [(27.825287, 3.9812808)]]\n",
      "4 [25.228262, 3.703028, [(25.228262, 3.703028)]]\n",
      "5 [22.873621, 3.4507453, [(22.873623, 3.4507453)]]\n",
      "6 [20.738752, 3.2220092, [(20.73875, 3.2220092)]]\n",
      "7 [18.803137, 3.0146217, [(18.803137, 3.0146217)]]\n",
      "8 [17.048176, 2.8265903, [(17.048176, 2.8265903)]]\n",
      "9 [15.457013, 2.6561086, [(15.457014, 2.6561086)]]\n",
      "10 [14.014359, 2.5015385, [(14.01436, 2.5015385)]]\n",
      "11 [12.706352, 2.361395, [(12.706352, 2.361395)]]\n",
      "12 [11.520427, 2.2343314, [(11.520427, 2.2343314)]]\n",
      "13 [10.445186, 2.119127, [(10.445185, 2.119127)]]\n",
      "14 [9.470302, 2.0146751, [(9.470302, 2.0146751)]]\n",
      "15 [8.586407, 1.9199722, [(8.586407, 1.9199722)]]\n",
      "16 [7.785009, 1.8341081, [(7.785009, 1.8341081)]]\n",
      "17 [7.0584083, 1.756258, [(7.0584083, 1.756258)]]\n",
      "18 [6.399624, 1.685674, [(6.399624, 1.685674)]]\n",
      "19 [5.8023257, 1.6216778, [(5.8023252, 1.6216778)]]\n",
      "20 [5.260776, 1.5636545, [(5.260776, 1.5636545)]]\n",
      "21 [4.7697697, 1.5110468, [(4.7697697, 1.5110468)]]\n",
      "22 [4.324591, 1.4633491, [(4.324591, 1.4633491)]]\n",
      "23 [3.9209633, 1.4201032, [(3.9209635, 1.4201032)]]\n",
      "24 [3.5550067, 1.3808936, [(3.5550067, 1.3808936)]]\n",
      "25 [3.2232056, 1.3453435, [(3.2232056, 1.3453435)]]\n",
      "26 [2.9223735, 1.3131114, [(2.9223735, 1.3131114)]]\n",
      "27 [2.6496189, 1.2838877, [(2.6496186, 1.2838877)]]\n",
      "28 [2.4023216, 1.2573916, [(2.4023216, 1.2573916)]]\n",
      "29 [2.178105, 1.2333684, [(2.178105, 1.2333684)]]\n",
      "30 [1.9748148, 1.2115873, [(1.9748147, 1.2115873)]]\n",
      "31 [1.7904993, 1.1918392, [(1.7904994, 1.1918392)]]\n",
      "32 [1.623386, 1.1739342, [(1.6233861, 1.1739342)]]\n",
      "33 [1.4718695, 1.1577003, [(1.4718695, 1.1577003)]]\n",
      "34 [1.3344955, 1.1429816, [(1.3344957, 1.1429816)]]\n",
      "35 [1.2099417, 1.1296366, [(1.2099419, 1.1296366)]]\n",
      "36 [1.0970144, 1.1175373, [(1.0970144, 1.1175373)]]\n",
      "37 [0.9946267, 1.1065671, [(0.9946267, 1.1065671)]]\n",
      "38 [0.90179497, 1.0966209, [(0.901795, 1.0966209)]]\n",
      "39 [0.8176275, 1.087603, [(0.81762755, 1.087603)]]\n",
      "40 [0.7413151, 1.0794266, [(0.7413151, 1.0794266)]]\n",
      "41 [0.67212623, 1.0720135, [(0.67212623, 1.0720135)]]\n",
      "42 [0.609394, 1.0652922, [(0.609394, 1.0652922)]]\n",
      "43 [0.5525169, 1.0591983, [(0.5525169, 1.0591983)]]\n",
      "44 [0.50094914, 1.0536731, [(0.50094914, 1.0536731)]]\n",
      "45 [0.45419374, 1.0486636, [(0.45419377, 1.0486636)]]\n",
      "46 [0.41180158, 1.0441216, [(0.41180158, 1.0441216)]]\n",
      "47 [0.37336722, 1.0400037, [(0.37336725, 1.0400037)]]\n",
      "48 [0.33851996, 1.03627, [(0.33852, 1.03627)]]\n",
      "49 [0.30692515, 1.0328848, [(0.30692515, 1.0328848)]]\n",
      "50 [0.27827826, 1.0298156, [(0.2782783, 1.0298156)]]\n",
      "51 [0.25230527, 1.0270327, [(0.25230527, 1.0270327)]]\n",
      "52 [0.2287569, 1.0245097, [(0.2287569, 1.0245097)]]\n",
      "53 [0.20740573, 1.022222, [(0.20740573, 1.022222)]]\n",
      "54 [0.18804836, 1.020148, [(0.18804836, 1.020148)]]\n",
      "55 [0.17049654, 1.0182675, [(0.17049655, 1.0182675)]]\n",
      "56 [0.15458433, 1.0165626, [(0.15458433, 1.0165626)]]\n",
      "57 [0.14015675, 1.0150168, [(0.14015675, 1.0150168)]]\n",
      "58 [0.12707591, 1.0136153, [(0.12707591, 1.0136153)]]\n",
      "59 [0.11521538, 1.0123445, [(0.11521538, 1.0123445)]]\n",
      "60 [0.10446167, 1.0111923, [(0.10446167, 1.0111923)]]\n",
      "61 [0.09471202, 1.0101477, [(0.09471202, 1.0101477)]]\n",
      "62 [0.08587202, 1.0092006, [(0.08587202, 1.0092006)]]\n",
      "63 [0.07785805, 1.0083419, [(0.07785805, 1.0083419)]]\n",
      "64 [0.07059129, 1.0075634, [(0.07059129, 1.0075634)]]\n",
      "65 [0.06400236, 1.0068574, [(0.06400236, 1.0068574)]]\n",
      "66 [0.05802846, 1.0062174, [(0.05802846, 1.0062174)]]\n",
      "67 [0.052612226, 1.005637, [(0.052612226, 1.005637)]]\n",
      "68 [0.047702473, 1.005111, [(0.047702473, 1.005111)]]\n",
      "69 [0.043249767, 1.0046339, [(0.043249767, 1.0046339)]]\n",
      "70 [0.03921318, 1.0042014, [(0.03921318, 1.0042014)]]\n",
      "71 [0.035553534, 1.0038093, [(0.035553537, 1.0038093)]]\n",
      "72 [0.032236177, 1.0034539, [(0.03223618, 1.0034539)]]\n",
      "73 [0.029227654, 1.0031315, [(0.029227655, 1.0031315)]]\n",
      "74 [0.02649951, 1.0028392, [(0.02649951, 1.0028392)]]\n",
      "75 [0.024025917, 1.0025742, [(0.024025917, 1.0025742)]]\n",
      "76 [0.021783749, 1.002334, [(0.02178375, 1.002334)]]\n",
      "77 [0.01975123, 1.0021162, [(0.019751232, 1.0021162)]]\n",
      "78 [0.017907381, 1.0019187, [(0.017907381, 1.0019187)]]\n",
      "79 [0.016236702, 1.0017396, [(0.016236704, 1.0017396)]]\n",
      "80 [0.014720838, 1.0015773, [(0.014720838, 1.0015773)]]\n",
      "81 [0.01334699, 1.00143, [(0.013346991, 1.00143)]]\n",
      "82 [0.012100856, 1.0012965, [(0.012100856, 1.0012965)]]\n",
      "83 [0.010971785, 1.0011755, [(0.010971785, 1.0011755)]]\n",
      "84 [0.0099481745, 1.0010659, [(0.0099481745, 1.0010659)]]\n",
      "85 [0.009018898, 1.0009663, [(0.009018898, 1.0009663)]]\n",
      "86 [0.008176883, 1.0008761, [(0.008176884, 1.0008761)]]\n",
      "87 [0.007413149, 1.0007943, [(0.007413149, 1.0007943)]]\n",
      "88 [0.006721576, 1.0007201, [(0.006721576, 1.0007201)]]\n",
      "89 [0.0060940585, 1.0006529, [(0.0060940585, 1.0006529)]]\n",
      "90 [0.005525271, 1.000592, [(0.0055252714, 1.000592)]]\n",
      "91 [0.0050098896, 1.0005368, [(0.0050098896, 1.0005368)]]\n",
      "92 [0.004542589, 1.0004867, [(0.004542589, 1.0004867)]]\n",
      "93 [0.0041189194, 1.0004413, [(0.0041189194, 1.0004413)]]\n",
      "94 [0.0037339528, 1.0004001, [(0.003733953, 1.0004001)]]\n",
      "95 [0.0033854644, 1.0003628, [(0.0033854644, 1.0003628)]]\n",
      "96 [0.0030694802, 1.0003289, [(0.0030694804, 1.0003289)]]\n",
      "97 [0.0027837753, 1.0002983, [(0.0027837753, 1.0002983)]]\n",
      "98 [0.0025234222, 1.0002704, [(0.0025234222, 1.0002704)]]\n",
      "99 [0.0022875469, 1.0002451, [(0.0022875469, 1.0002451)]]\n"
     ]
    }
   ],
   "source": [
    "X = [1,2,3]\n",
    "Y = [1,2,3]\n",
    "\n",
    "# Set wrong model weights\n",
    "W = tf.Variable(5.)\n",
    "# Linear model\n",
    "hypothesis = X * W\n",
    "# Manual gradient\n",
    "gradient = tf.reduce_mean((W * X - Y) * X ) * 2\n",
    "# cost/Loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "\n",
    "\n",
    "# Get gradients\n",
    "gvs = optimizer.compute_gradients(cost, [W])\n",
    "# Apply gradients\n",
    "apply_gradients = optimizer.apply_gradients(gvs)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    print(step, sess.run([gradient, W, gvs]))\n",
    "    sess.run(apply_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.666664 1.2666664\n",
      "0.3318512 1.0177778\n",
      "0.0014748968 1.0011852\n",
      "6.555027e-06 1.000079\n",
      "2.91322e-08 1.0000052\n",
      "1.2839034e-10 1.0000004\n",
      "5.163277e-13 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = [1,2,3]\n",
    "y = [1,2,3]\n",
    "\n",
    "w = tf.Variable(5.0)\n",
    "\n",
    "hypo = x*w\n",
    "cost = tf.reduce_mean(tf.square(hypo-y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    cost_val, w_val, _ = sess.run([cost, w, train])\n",
    "    print(cost_val, w_val)\n",
    "#     print(step, sess.run(w))\n",
    "#     sess.run(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
